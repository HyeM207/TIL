# Logstash
책 '엘라스틱 스택 개발부터 운영까지 - 김준영/정상운 지음'을 공부하며 정리하였습니다.  

</br>

# 1. Logstash
플러그인 기반의 오픈소스 데이터 처리 파이프라인 도구  
- `플러그인 기반`
    - Logstash의 파이프라인의 각 요소 모두 플러그인 형태로 만들어져있고, 기본 플러그인 외에도 많은 커뮤니티 플러그인들이 있음
- `모든 형태의 데이터처리` 
    - 기본 플러그인 만으로도 데이터 소스에서 구조화/비구조화 데이터 입력받아 가공 후 저장 가능함 
    - 특히 시간에 따라 발생하는 데이터 처리에 최적화되어 있음
- 높은 성능
    - `자체 내장 메모리와 파일 기반의 큐`를 사용하여 처리 속도와 안정성이 높음
    - 인덱싱 도큐먼트 수와 용량을 종합적 고려해 벌크 인덱싱 수행하고, 파이프라인 배치 크기 조정을 통해 병목현상을 방지하고 성능 최적화 가능
- 안정성
    - Elasticsearch의 장애 상황에 대응하기 위해, 재시도 로직이나 오류가 발생한 도큐먼트를 따로 보관하는 `데드 레터 큐`를 내장함
    - 파일 기반 큐 사용시, Logstash 장애 상황에서 도큐먼트 유실 최소화 가능

</br></br>

# 2. 파이프라인
## 2.1 파이프라인
> 파이프라인 소개

Logstash의 가장 중요한 부분으로, 파이프라인은 데이터를 입력받아 실시간으로 변경하고 이를 다른 시스템에 전달하는 역할을 한다.  

구성요소는 크게 `입력`, `필터`, `출력` 세 가지로 구성된다. (입력과 출력은 필수, 필터는 선택)   
</br>

> 파이프라인 실행 순서
```
데이터 소스 → [ 입력 → 필터 → 출력 ] → Elasticsearch
            ↳ Logstash Pipeline ↲ 
```
- 입력 (필수) : 소스로부터 데이터를 받아들이는 모듈  
- 필터 (선택) : 입력으로 들어오는 데이터를 원하는 형태로 가공하는 모듈  
- 출력 (필수) : 데이터를 외부로 전달하는 모듈  

</br>

> Logstash 실행 방법과 예시

Logstash가 설치된 폴더의 bin 폴더에서 logstash.bat 실행하면 된다. 또한, Logstash를 실행하기 위해서는 반드시 파이프라인 설정이 필요하다.   
예시로 CMD에서 다음 명령을 입력하여 표준 입력으로 전달받은 메시지를 다시 표준 출력으로 표시하는 파이프라인 예시이다. 

```
.\bin\logstash.bat -e "input { stdin { } } output { stdout { } }"
```

<br>실행 후 'hello hyem'을 입력하면 다음과 같이 결과가 출력된다.
```
{
    "@version" => "1",
     "host" => "DESTOP-0000000",
    "message" => "hello hyem\r",
    "@timestamp" => 2023-01-04T23:39:11.242Z
}
```
- 로그 스태시는 `JSON 형태`로 데이터 출력함 
- @version과 @timestamp는 logstash가 만든 필드
- `@` 기호는 logstash에 의해 생성된 필드, 안 붙은 필드는 수집을 통해 얻어진 정보다
- 간단한 파이프라인의 경우 위처럼 콘솔로 직접 입력가능하지만, 작업 이력관리를 위해 `pipeline.yml`이나 `파이프라인 설정 파일`을 만들어 logstash를 동작하는 것이 좋다 


</br>

> 파이프라인 기본 템플릿
```
input{
        { 입력 플러그인 }
}

filter {
    { 필터 플러그인 }
}
output {
    { 출력 플러그인 }
}
```
파이프라인 구성요소인 입력, 필터, 출력의 내부에 플러그인 지정 가능하다.   
용도나 형태에 맞춰 이미 만들어진 많은 플러그인이 있어 필요한 기능의 플러그인을 검색하여 템플릿을 추가하면 된다.

</br></br>

## 2.2 입력
> 입력 파트

Logstash의 가장 앞부분에 위치하여, 소스 원본으로부터 데이터를 입력받는 단계이다.

Logstash 입력이 받아들일 수 있는 데이터 소스들은 파일, 웹, 데이터베이스, 스트림 등 다양하다.

<br>

> 입력 플러그인

Logstash는 다양한 형태의 데이터를 쉽게 처리하기 위해 다양한 입력 플러그인들이 존재한다.  
 전체 입력 플러그인은 [공식 문서](https://www.elastic.co/guide/en/logstash/8.6/input-plugins.html)에서 확인 가능하고, `file`, `syslog`, `kafka`, `jdbc`가 자주 사용하는 입력 플러그인이다. 

| 플러그인 | 설명 | 
| -----  | ----- | 
| `file` | 리눅스의 tail -f 명령처럼 파일을 스트리밍하며 이벤트를 읽어들임|
| `syslog` | 네트워크를 통해 전달되는 시스로그를 수신함 | 
| `kafka`  | 카프카의 토픽에서 데이터를 읽어들임 |
| `jdbc` | JDBC 드라이버로 지정된 일정마다 쿼리를 실행해 결과를 읽어들임 | 


<br><br>

 
## 2.3 필터
> 소개

필터는 선택적인 구성요소로, 입력 플러그인이 받은 데이터를 의미있는 데이터로 구조화하는 역할을 한다.  
필터 역시 플러그인 형태이며, 다양한 필터 플러그인 형태가 존재한다. 전체 플러그인은 [공식 문서](https://www.elastic.co/guide/en/logstash/8.6/filter-plugins.html)에서 확인 가능하고, `grok`, `dissect`, `mutate`, `date`가 자주 사용되는 필터 플러그인이다.   

| 플러그인 | 설명 | 
| -----  | ----- | 
| `grok` | 메시지를 구조화된 형태로 분석함. grok패턴은 정규식과 유사하나, 추가적으로 미리 정의된 패턴이나 필드 이름 설정, 데이터 타입 정의 등을 도와줌 | 
| `dissect` | 간단한 패턴을 이용해 메시지를 구조화 형태로 분석함. 자유도는 떨어지지만 더 빠른 처리 가능 | 
| `mutate`| 필드명 변경, 문자열 처리 등 일반적인 가공 함수들 제공 |
| `date` | 문자열을 지정한 패턴의 날자형으로 분석함 | 

<br><br>

 
## 2.4 출력
> 소개

출력은 필수 구성요소로, 파이프라인의 입력과 필터를 거쳐 가공된 데이터를 지정한 대상으로 내보내는 단계이다.    
출력 역시 플러그인 형태이며, 다양한 필터 플러그인 형태가 존재한다. 전체 플러그인은 [공식 문서](https://www.elastic.co/guide/en/logstash/8.6/output-plugins.html)에서 확인 가능하고, `elasticsearch`, `file`, `kafka`가 자주 사용되는 필터 플러그인이다. 


| 플러그인 | 설명 | 
| -----  | ----- | 
| `elasticsearch` | 가장 많이 사용되는 출력 플러그인으로, bulk API를 사용해 엘라스틱 서치에 인덱싱을 수행함 | 
| `file` | 지정한 파일의 새로운 줄에 데이터를 기록함 | 
| `kafka`  | 카프카 토픽에 데이터를 기록함 | 

</br></br>

## 2.5 코덱
코덱은 독립적으로 동작하지 않고, 입력과 출력 과정에 사용되는 플러그인으로, 입/출력 시 메시지를 적절한 형태로 변환하는 스트림 필터이다.  
자주 사용하는 플러그인은 다음과 같다.

| 플러그인 | 설명 | 
| -----  | ----- | 
| `json` | 입력 시 JSON 형태로 객체를 읽어들이고, 출력 시에는 이벤트 객체를 다시 JSON 형태로 변환함 | 
| `plain` | 메시지를 단순 문자열로 읽어들이고, 출력 시에는 원하는 포멧을 지정 가능함| 
| `ruby debug` | 로그스태시의 설정을 테스트하거나 예상치 못한 파이프라인 설정 오류를 디버깅하기 위한 목적으로 주로 사용되며, 출력 시 ruby 언어의 해시 형태로 이벤트를 기록함. 입력 시에는 사용 안 함 | 

</br></br>

# 3. 다중 파이프라인
> 개념 

하나의 Logstash에서 여러 개의 파이프라인을 동작할 수있다. 로그 입수 경로가 다양해지는 경우 각각의 파이프라인을 만들어 동작할 수 있다.  

<br>

> 작성 방법

1. config 폴더의 `pipelines.yml`파일을 수정하여, 다중 파이프라인을 가능하게 한다. 
```
- pipeline.id : pipeline1
- path.config : "/logstash-7.10.1/config/mypipe1.conf"
- pipeline.id : pipeline2
- path.config : "/logstash-7.10.1/config/mypipe2.conf"
```  

<details><summary>파이프라인 설정</summary>

| 설정 | 설명 | 
| -----  | ----- |  
| pipeline.id | 파이프라인의 고유 id |
| path.config | 파이프라인 설정 파일 위치 |
| pipeline.workers | 필터와 출력을 병렬로 처리하기 위한 워커 수 (기본적으로 호스트의 CPU 코어 수와 동일하게 설정됨) |
| pipeline.batch.size | 입력시 하나의 워커당 최대 몇 개까지의 이벤트를 동시에 처리할 지 결정함|
| queue.type | 파이프라인에서 사용할 큐의 종류 설정. 기본적으로 memory 타입이 사용되나 persisted 타입을 선택해 이벤트 유실 최소화 가능함 |
</details>
<br>

2. 각 파이프라인의 설정 파일을 작성한다.
위의 예시에 따르면 mypipe1.conf와 mypipe2.conf를 각각 작성한다. 

3. 실행은 별다른 옵션 없이 `./bin/logstash.bat`을 실행하면 된다.   
    - Logstash를 실행하면 기본적으로 pipelines.yml에 정의되어 있는 파이프라인을 인식함으로 별 다른 옵션이나 인자 없이 실행할 수 있다. 

</br></br>

# 4. 모니터링
> 종류 

Logstash를 모니터링 하는 방법은 2가지이다.  
1. Logstash가 제공하는 API 활용해 특정 시점의 통계 정보를 얻는 방법
2. 모니터링 기능을 활성화해서 지속적인 통계 정보를 수집하고, Kibana를 통해 대시보드 형태로 연속적인 모니터링 수행하는 방법

<br>

> 종류 1. API 활용하기
API 활용시 설정 변경이나 시스템을 재시작 필요가 없다. 

Logstash API 리스트는 다음과 같다.
| 정보 | 사용법 |
| ---- | -----|
| 노드 | curl - XGET 'localhost:9600/_node?pretty' |
| 플러그인 | curl - XGET 'localhost:9600/_node/plugins?pretty' |
| 노드 통계 | curl - XGET 'localhost:9600/_node/stats?pretty' |
| 핫 스레드 | curl - XGET 'localhost:9600/_node/hot_threads/pretty' |

- 노드 : Logstash가 실행되고 있는 노드의 기본 정보를 제공하는데 크게 파이프라인, OS, JVM 정보를 제공함
- 플러그인 : Logstash에서 사용하는 플러그인 정보를 제공함
- 노드 통계 : 파이프라인, 이벤트, 프로세스 등의 Logstash 정보 제공
    - 파이프라인을 구성하는 플러그인 정보와 Logstash에서 입력, 출력 정보가 통계화되어 보이기에, 파이프라인 구성요소 중 어떤 구간에 병목이 있는지 등을 확인하는데 용이함
- 핫 스레드 : CPU 사용량이 많은 스레드를 높은 순으로 보여주는데 문제 발생 시 원인을 찾는데 유용함

<br>

> 종류 2. 모니터링 기능 활성화

모니터링 기능을 활성화하면 Logstash 통계 데이터를 ElasticSearch에 전송하고, Kibana GUI를 이용해 모니터링 정보를 연속적으로 파악할 수 있다. 

사용을 위해서는 Logstash의 config의 폴더의 logstash.yml파일을 수정해야한다.
- xpack.monitoring.enabled = true
- xpack.monitoring.elasticsearch.hosts를 로컬호스트로 변경

설정을 바꾼 후에는 Kibana에 접속하여 `stack monitoring`을 선택하고 스택 모니터링 UI를 활성화하여 확인할 수 있다.

</br></br>

# 5. 기타 설정
> Heap 설정

Logstash의 config 폴더의 `jvm.options`에서 최대 힙 메모리 크기를 설정할 수 있다.
- Xms : 초기 힙 크기 
- Xmx : 최대 힙 크기 

힙 크기를 높게 설정하면 캐싱을 많이하여 Logstash의 성능을 높일 수 있지만, 노드 전체의 메모리를 고려해 설정해야한다. 


<sub>자바는 `가비지 컬렉션` 기능이 있어, 메모리 사용량이 일정 수준 이상 올라가면 메모리 정리를 해준다. 메모리가 올라가다가 GC에 의해 다시 낮아지는 것을 모니터링 기능을 이용하면 확인할 수 있다. </sub> 