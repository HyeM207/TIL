# Kafka
책 '아파치 카프카 애플리케이션 프로그래밍 with 자바 - 최원영 지음'을 공부하며 정리하였습니다.    
- [Kafka](#kafka)
- [1. Kafka](#1-kafka)
  * [1.1 Kafka 탄생 배경](#11-kafka------)
  * [1.2 Kafka 특징](#12-kafka---)
- [2. Kafka 컴포넌트](#2-kafka-----)
  * [2.2 카프카 브로커·클러스터·주키퍼](#22-----------------)
    + [(1) 카프카 브로커](#-1---------)
    + [(2) 카프카 클러스터](#-2----------)
    + [(3) 데이터 전송과 저장](#-3------------)
    + [(4) 데이터 복제, 싱크](#-4------------)
    + [(5) 컨트롤러](#-5------)
    + [(6) 데이터 삭제](#-6--------)
    + [(7) 컨슈머 오프셋 저장](#-7------------)
    + [(8) 코디네이터](#-8-------)
    + [(9) 주키퍼](#-9-----)

</br>

# 1. Kafka
## 1.1 Kafka 탄생 배경 
> 당시 상황 

2011년 당시, 단방향 통신을 통해 소스 애플리케이션엣어 타깃 애플리케이션으로 연동하는 소스코드를 작성하는 식으로 데이터 수집 및 분배 아키텍처를 운영했다. 
이러한 구조는 아키텍처가 거대해지고, 소스 애플리케이션과 타깃 애플리케이션을 연결하는 파이프라인 개수가 많아지면서 소스버전/버전 관리 이슈가 그대로 전달 되었다.

> 탄생

링크드인 데이터팀은 이러한 상황에서 신규 시스템인 Kafka를 만들었다. Kafka는 한 곳에 모아 처리할 수 있도록 중앙 집중화하여 데이터 스트림을 한 곳에서 실시간으로 관리할 수 있게 되었다.  
kafka르 중앙에 배치함으로써 소스 애플리케이션과 타깃 애플리케이션 사이의 `의존도를 최소화`하여 `커플링을 완화`하였다.

<br>

## 1.2 Kafka 특징 
높은 처리량, 확장성, 영속성, 고가용성 특징을 가진 카프카는 데이터 파이프라인을 안전하고 확장성 높게 운영할 수 있도록 설계되었다.

1. `높은 처리량`
    - 카프카는 프로듀서가 브로커로 데이터를 보낼때와 컨슈머가 브로커로부터 데이터를 받을 때 모두 `묶어서 전송`한다. 이는 네트워크 통신 횟수를 최소한으로 줄이고, 많은 양의 데이터를 묶음단위로 처리하는 `배치`도 빠르게 처리할 수 있다.  
    - 파티션 단위를 통해 동일 목적의 데이터를 `여러 파티션에 분배`하고 데이터를 `병렬 처리`할 수 있다. 
2. `확장성`
    - input 데이터의 양을 예측하기 힘든 가변적인 환경에서 `안정적으로 확장 가능`하다. 데이터가 많아지면 브로커 개수를 늘려 `스케일 아웃(scale-out)`하고, 데이터가 적어지면 브로커 개수를 줄여 `스케일 인(scale-in)`할 수 있다.
3. `영속성`
    - 카프카는 다른 메시징 플랫폼과 다르게 전송받은 데이터를 메모리가 아닌 `파일 시스템에 저장`한다. 카프카는 운영체제에서 파일 I/O 성능 향상을 위해 `페이지 캐시`영역을 메모리에 따로 생성하여 사용한다. 
    - 디스크 기반의 파일시스템을 활용한 덕분에 브로커가 장애발생으로 급작스럽게 종료되어도 `프로세스를 재시작`하여 안전하게 `데이터를 다시 처리`할 수 있다.  
4. `고가용성`
    - 3개 이상의 서버로 운영되는 `카프카 클러스터`는 일부 서버에 장애가 발생하더라도 `무중단`으로 안전하고 지속적으로 데이터를 처리할 수 있다.
    - 카프카는 클러스터는 `데이터 복제(replication)`를 통해 고가용성의 특징을 가진다. 

<sub>영속성이란 데이터를 생성한 프로그램이 종료되더라도 사라지지 않은 데이터의 특성을 의미한다.</sub>  
<sub>페이지 캐시 메모리 영역을 사용하여 한번 읽은 파일 내용은 메모리에 저장시켰다가 다시 사용하기 때문에, 파일시스템에 데이터를 저장하더라도 처리량이 높다.</sub>

</br></br>

# 2. Kafka 컴포넌트
## 2.2 카프카 브로커·클러스터·주키퍼
### (1) 카프카 브로커
카프카 브로커는 카프카 클라이언트과 데이터를 주고받기 위해 사용되는 주체이자,데이터를 `분산 저장`하여 장애가 발생하더라도 안전하게 사용할 수 있도록 도와주는 애플리케이션이다.   
`하나의 서버`에는 `하나의 카프카 브로커 프로세스`가 실행된다.   
<br>

### (2) 카프카 클러스터
브로커 서버 1대로도 운영은 가능하나, 데이터를 안전하게 보관하고 처리하기 위해 `3대 이상의 브로커 서버`를 `1개의 클러스터`로 묶어서 운영한다.  
카프카 클러스터로 묶은 브로커들은 프로듀서가 보낸 데이터를 안전하게 `저장하고 복제`하는 역할을 수행한다.  
<br>

### (3) 데이터 전송과 저장
`프로듀서`로 부터 데이터를 전달받으면 브로커는 프로듀서가 요청한 `토픽의 파티션`에 데이터를 저장하고, `컨슈머`가 데이터를 요청하면 파티션에 저장된 데이터를 전달한다.  
데이터 저장은 `파일시스템에 저장`되며,`페이지 캐시`를 사용하여 디스크 입출력 속도를 높여서 속제 문제를 해결했다.   
<br>

### (4) 데이터 복제, 싱크
`데이터 복제(replication)`는 카프카를 `장애 허용 시스템(fault tolerant system)`으로 동작하도록 하는 원동력이다.

카프카 복제는 `파티션` 단위로 이뤄진다. 

<details><summary>세부 설명</summary>

- 토픽을 생성할 때 파티션 복제 개수를 설정되고, 직접 옵션을 선택하거나 브로커의 기본 설정으로 설정된다. 
- 복제 개수 최솟값은 1(복제없음)이고, 최댓값은 브로커 개수이다.
- 복제된 파티션은 `리더(leader)`와 `팔로워(follower)`로 구성된다. 
    - 리더 : 프로듀서와 컨슈머와 직접 통신하는 파티션 
    - 팔로워 : 나머지 복제 데이터를 갖고 있고 있는 파티션
    - 팔로워 파티션들은 리더 파티션의 `오프셋`을 확인하여 현재 자신이 가지고 있는 오프셋과 차이나는 경우 리더 파티션으로부터 데이터를 가져와서 자신의 파티션에 저장한다. ⇒ <b>`복제(replication)`</b>
- 브로커에 장애가 발생하면, 해당 브로커에 있는 리더 파티션은 사용할 수 없기 때문에 팔로워 파티션 중 하나가 `리더 파티션 지위를 넘겨받는다.`
- 운영 시 데이터 종류마다 다른 복제 개수를 설정하고, 상황에 따라 토픽마다 복제 개수를 다르게 설정하여 운영한다. 
    - 데이터가 일부 유실되도 무관하고 데이터 처리 속도가 중요하다면 `1 or 2`로 설정한다.
    - 중요 정보 등 유실이 안 되는 데이터의 경우 복제 개수를 `3`으로 설정한다.

</details>


<br>


### (5) 컨트롤러
`클러스터`의 다수 브로커 중 `한 대`가 컨트롤러 역할을 한다.   
컨트롤러는 다른 `브로커들의 상태를 체크`하고 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 `리더 파티션을 재분배`한다.  
만약 컨트롤러 역할을 하는 브로커에 장애가 생기면 다른 브로커가 컨트롤러 역할을 한다.   

<br>


### (6) 데이터 삭제 
카프카는 다른 메시진 플랫폼과 다르게 컨슈머가 데이터를 가져가더라도 토픽의 데이터는 삭제되지 않으며, 컨슈머나 프로듀서가 데이터 삭제를 요청할 수 없다.  
오직 `브로커`만이 데이터를 삭제할 수 있다.  

데이터 삭제는 파일 단위로 이뤄지는데, 이 단위를 `로그 세그먼트(log segment)`라고 부른다. 세그먼트에는 다수의 데이터가 들어있기 때문에 특정 데이터를 삭제할 수 없다.  

세그먼트는 데이터가 쌓이는 동안 파일시스템으로 열려있지만, 카프카 브로커에 `log.segment.bytes` 또는 `log.segment.ms` 옵션에 값이 설정되면 세그먼트 파일이 닫힌다.  
닫힌 세그먼트 파일은 `log.retention.bytes` 또는 `log.retention.ms`옵션에 설정값이 넘으면 삭제된다.  

<sub> - 세그먼트가 닫히는 기본값은 1GB 용량에 도달했을 때인데 간격을 줄이고 싶으면 작은 용량으로 설정하면 된다.   단, 데이터를 저장하는동안 잦은 세그먼트 여닫힘은 부하를 발생할 수 있으므로 주의해야한다.</sub>  
<sub> - 닫힌 세그먼트 파일을 체크하는 간격은 브로커 옵션의 `log.retention.check.interval.ms`에 따른다.</sub>

<br>

### (7) 컨슈머 오프셋 저장
`컨슈머 그룹`은 토픽이 특정 파티션으로부터 데이터를 가져사거 처리하고 이 파티션의 `어느 레코드까지 가져갔는지` 확인하기 위해 오프셋을 커밋한다.  
커밋한 오프셋은 `_consumer_offsets` 토픽에 저장한다.  

<br>

### (8) 코디네이터
`클러스터`의 다수 크로커 중 `한 대`는 코디네이션 역할을 수행한다.  
코디네이터는 `컨슈머 그룹의 상태를 체크`하고 `파티션을 컨슈머와 매칭되도록 분배`하는 역할을 한다.   

`리벨런스(rebalance)` : 파티션을 컨슈머로 재할당하는 과정. 컨슈머가 컨슈머 그룹에서 빠지면, 매칭되지 않은 파티션을 정상 동작하는 컨슈머로 할당하여 끊임없이 데이터가 처리되도록 도와준다.

<br>


### (9) 주키퍼
주키퍼는 `카프카의 메타데이터를 관리`하는데 사용된다. 어떤 데이터를 저장하느지 확인할 수 있고, 생성된 토픽 등도 확인 가능하다.

카프카 클러스터로 묶은 브로커들은 동일한 경로의 주키퍼 경로로 선언해야 같은 카프카 브로커 묶음이 된다. 만약 클러스터를 여러개로 운영한다면 한 개의 주키퍼에 다수의 카프카 클러스터를 연결해서 사용할 수도 있다.

